<!-- sensor_robot_enable.launch -->
<launch>
    <!-- Launch realsense2_camera for head camera -->
    <include file="$(find realsense2_camera)/launch/rs_camera.launch" >
        <arg name="color_width"   value="1280"/>
        <arg name="color_height"  value="720"/>
        <arg name="color_fps"     value="30"/>
        <arg name="depth_width"   value="1280"/>
        <arg name="depth_height"  value="720"/>
        <arg name="depth_fps"     value="30"/>
        <arg name="enable_infra"        default="false"/>
        <arg name="enable_infra1"       default="false"/>
        <arg name="enable_infra2"       default="false"/>
        <arg name="enable_sync"   value="true"/>
        <arg name="align_depth"   value="true"/>
        <arg name="enable_pointcloud"   value="false"/>
    </include>
    
    <!-- tf2_ros 静态转换 发布urdf里面的head_camera 和 相机坐标系下的camera_link 进行对齐 -->
    <node pkg="tf2_ros" type="static_transform_publisher" name="camera_to_real_frame" args="0 0 0 0 0 0 head_camera camera_link" />

    <!-- 启动yolov5 目标检测 及 分割节点 -->
    <node pkg="kuavo_vision_object" type="realsense_yolo_segment_ros.py" name="realsense_yolo_segment_node" output="screen">
    </node>

    <!-- 启动yolov5 目标转换功能 -->
    <node pkg="kuavo_vision_object" type="realsense_yolo_transform_torso.py" name="realsense_yolo_transform_torso_node" output="screen">
    </node>

    <!-- 启动yolov5 点云分割节点 -->
    <node pkg="kuavo_yolo_point2d" type="point_cloud_mask_node.py" name="point_cloud_mask_node" output="screen">
    </node>
</launch>
